"""
test_historical_depth.py
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–ª—É–±–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ï–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –±–∞–Ω–∫–∞ (ECB).
–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–∞–º—É—é —Ä–∞–Ω–Ω—é—é –¥–æ—Å—Ç—É–ø–Ω—É—é –¥–∞—Ç—É –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–ª—é—Ç—ã.
"""

import sys
import requests
import time
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime, date
from collections import defaultdict

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ECB API ---
ECB_HISTORICAL_XML_URL = "https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.xml"
ECB_HIST_90D_URL = "https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist-90d.xml"
REQUEST_TIMEOUT = 30
REQUEST_DELAY = 0.1

def find_latest_coverage_file():
    """–ò—â–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞ –æ –ø–æ–∫—Ä—ã—Ç–∏–∏."""
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    possible_dirs = [
        Path("data/research_results/ecb"),
        Path(__file__).parent.parent.parent / "data" / "research_results" / "ecb",
    ]
    
    coverage_dir = None
    for dir_path in possible_dirs:
        if dir_path.exists():
            coverage_dir = dir_path
            break
    
    if not coverage_dir:
        print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ test_ecb_coverage.py")
        sys.exit(1)
    
    coverage_files = list(coverage_dir.glob("coverage_report_*.json"))
    if not coverage_files:
        print(f"‚ùå –í {coverage_dir} –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ coverage_report_*.json")
        print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ test_ecb_coverage.py")
        sys.exit(1)
    
    latest_file = max(coverage_files, key=lambda f: f.stat().st_mtime)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç—á–µ—Ç –æ –ø–æ–∫—Ä—ã—Ç–∏–∏: {latest_file}")
    return latest_file

def load_coverage_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ –ø–æ–∫—Ä—ã—Ç–∏—è."""
    latest_coverage_path = find_latest_coverage_file()
    
    with open(latest_coverage_path, 'r', encoding='utf-8') as f:
        coverage_data = json.load(f)
    
    available_currencies = coverage_data['analysis']['available_currencies']
    
    if not available_currencies:
        print("‚ö†Ô∏è  –í –æ—Ç—á–µ—Ç–µ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–∞–ª—é—Ç. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
        sys.exit(1)
    
    return available_currencies, latest_coverage_path

class ECBHistoryDepthTester:
    def __init__(self, currencies_to_test: List[str], coverage_report_path: Path):
        self.currencies = currencies_to_test
        self.coverage_report_path = coverage_report_path
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": "AbsCur3-Research/1.0"})
        
        self.history_depth = {}
        self.all_rates_by_date = defaultdict(dict)

    def fetch_historical_xml(self, url: str) -> Optional[ET.Element]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–∞—Ä—Å–∏—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π XML-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ ECB."""
        try:
            print(f"‚è¨ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑: {url}")
            response = self.session.get(url, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({len(response.content)} –±–∞–π—Ç)")
            
            namespaces = {
                'gesmes': 'http://www.gesmes.org/xml/2002-08-01',
                '': 'http://www.ecb.int/vocabulary/2002-08-01/eurofxref'
            }
            
            root = ET.fromstring(response.content)
            for prefix, uri in namespaces.items():
                if prefix:
                    ET.register_namespace(prefix, uri)
                else:
                    ET.register_namespace('', uri)
            
            return root
            
        except requests.exceptions.Timeout:
            print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö —Å {url}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
            return None
        except ET.ParseError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
            return None

    def analyze_currency_depth(self, root: ET.Element):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç XML, –Ω–∞—Ö–æ–¥—è —Å–∞–º—É—é —Ä–∞–Ω–Ω—é—é –∏ –ø–æ–∑–¥–Ω—é—é –¥–∞—Ç—É –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–ª—é—Ç—ã."""
        namespaces = {'ecb': 'http://www.ecb.int/vocabulary/2002-08-01/eurofxref'}
        
        # –ò—â–µ–º –≤—Å–µ –¥–Ω–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
        time_cubes = root.findall('.//ecb:Cube[@time]', namespaces)
        if not time_cubes:
            time_cubes = root.findall('.//{http://www.ecb.int/vocabulary/2002-08-01/eurofxref}Cube[@time]')
        
        print(f"üìÖ –ù–∞–π–¥–µ–Ω–æ {len(time_cubes)} –¥–Ω–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏.")
        
        earliest_date = {currency: None for currency in self.currencies}
        latest_date = {currency: None for currency in self.currencies}
        daily_count = {currency: 0 for currency in self.currencies}
        
        for day_cube in time_cubes:
            current_date_str = day_cube.get('time')
            try:
                current_date = datetime.strptime(current_date_str, "%Y-%m-%d").date()
            except ValueError:
                continue
            
            # –ò—â–µ–º –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –¥–ª—è —ç—Ç–æ–≥–æ –¥–Ω—è
            rate_cubes = day_cube.findall('ecb:Cube[@currency]', namespaces)
            if not rate_cubes:
                rate_cubes = day_cube.findall('{http://www.ecb.int/vocabulary/2002-08-01/eurofxref}Cube[@currency]')
            
            for rate_cube in rate_cubes:
                currency = rate_cube.get('currency')
                rate = rate_cube.get('rate')
                
                if currency in self.currencies:
                    self.all_rates_by_date[current_date_str][currency] = rate
                    
                    if earliest_date[currency] is None or current_date < earliest_date[currency]:
                        earliest_date[currency] = current_date
                    if latest_date[currency] is None or current_date > latest_date[currency]:
                        latest_date[currency] = current_date
                    
                    daily_count[currency] += 1
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        for currency in self.currencies:
            if earliest_date[currency] and latest_date[currency]:
                days_diff = (latest_date[currency] - earliest_date[currency]).days
                self.history_depth[currency] = {
                    'earliest_date': earliest_date[currency].isoformat(),
                    'latest_date': latest_date[currency].isoformat(),
                    'total_days': daily_count[currency],
                    'approx_years': round(days_diff / 365.25, 1)
                }
            else:
                self.history_depth[currency] = {
                    'earliest_date': None,
                    'latest_date': None,
                    'total_days': 0,
                    'approx_years': 0.0
                }

    def run_test(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∞."""
        print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –≥–ª—É–±–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö ECB...")
        
        xml_root = self.fetch_historical_xml(ECB_HISTORICAL_XML_URL)
        
        if xml_root is None:
            print("‚ö†Ô∏è  –ü—Ä–æ–±—É–µ–º —Ñ–∞–π–ª –∑–∞ 90 –¥–Ω–µ–π...")
            xml_root = self.fetch_historical_xml(ECB_HIST_90D_URL)
        
        if xml_root is None:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ.")
            return False
        
        print("üîé –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª—É–±–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–ª—é—Ç—ã...")
        self.analyze_currency_depth(xml_root)
        
        print("\n" + "=" * 60)
        print("–ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        for i, currency in enumerate(sorted(self.currencies), 1):
            depth_info = self.history_depth.get(currency, {})
            earliest = depth_info.get('earliest_date', '–ù/–î')
            years = depth_info.get('approx_years', 0)
            status = "‚úÖ" if earliest != '–ù/–î' and years > 20 else "‚ö†Ô∏è " if earliest != '–ù/–î' else "‚ùå"
            print(f"{status} [{i:2d}] {currency}: –ù–∞—á–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {earliest}, ~{years} –ª–µ—Ç")
        
        return True

    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ –≤ —Ñ–∞–π–ª—ã."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("data/research_results/ecb")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ JSON
        full_report = {
            "test_date": datetime.now().isoformat(),
            "source_xml": ECB_HISTORICAL_XML_URL,
            "currencies_tested": self.currencies,
            "history_depth": self.history_depth,
            "coverage_source_report": str(self.coverage_report_path.name)
        }
        
        report_path = output_dir / f"historical_depth_report_{timestamp}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, ensure_ascii=False, indent=2)
        
        # 2. –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        text_report = f"""–û–¢–ß–ï–¢ –û –ì–õ–£–ë–ò–ù–ï –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–• ECB
–î–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: {ECB_HISTORICAL_XML_URL}
–ò—Å—Ç–æ—á–Ω–∏–∫ —Å–ø–∏—Å–∫–∞ –≤–∞–ª—é—Ç: {self.coverage_report_path.name}

–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
-----------------
–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤–∞–ª—é—Ç: {len(self.currencies)}
–í–∞–ª—é—Ç —Å –¥–∞–Ω–Ω—ã–º–∏: {sum(1 for info in self.history_depth.values() if info['earliest_date'] is not None)}

–ö–†–ò–¢–ï–†–ò–ò –ü–†–û–ï–ö–¢–ê ABScur3:
------------------------
–¶–µ–ª–µ–≤–∞—è –≥–ª—É–±–∏–Ω–∞: 20+ –ª–µ—Ç (—Å ~2005 –≥–æ–¥–∞)
–í–∞–ª—é—Ç—ã —Å –∏—Å—Ç–æ—Ä–∏–µ–π >20 –ª–µ—Ç: {sum(1 for info in self.history_depth.values() if info.get('approx_years', 0) > 20)}

–î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –í–ê–õ–Æ–¢–ê–ú:
--------------------------------
"""
        sorted_currencies = sorted(
            self.history_depth.items(),
            key=lambda x: x[1]['earliest_date'] or '9999-99-99'
        )
        
        for currency, info in sorted_currencies:
            earliest = info['earliest_date'] or "–ù–ï–¢ –î–ê–ù–ù–´–•"
            latest = info['latest_date'] or "–ù–ï–¢ –î–ê–ù–ù–´–•"
            years = info['approx_years']
            days_count = info['total_days']
            
            if years >= 20:
                marker = "‚úì"
                years_status = f"~{years} –ª–µ—Ç (–¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê)"
            elif years > 0:
                marker = "‚ö†"
                years_status = f"~{years} –ª–µ—Ç (–ù–ï–î–û–°–¢–ê–¢–û–ß–ù–û)"
            else:
                marker = "‚úó"
                years_status = "–ù–ï–¢ –î–ê–ù–ù–´–•"
            
            text_report += f"\n{marker} {currency}:\n"
            text_report += f"   –ù–∞—á–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {earliest}\n"
            text_report += f"   –ö–æ–Ω–µ—Ü –¥–∞–Ω–Ω—ã—Ö:  {latest}\n"
            text_report += f"   –ì–ª—É–±–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏: {years_status}\n"
            text_report += f"   –í—Å–µ–≥–æ —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö: {days_count} –¥–Ω–µ–π\n"
        
        text_report_path = output_dir / f"historical_depth_summary_{timestamp}.txt"
        with open(text_report_path, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        # 3. –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤ CSV
        csv_path = output_dir / f"historical_depth_table_{timestamp}.csv"
        with open(csv_path, 'w', encoding='utf-8') as f:
            f.write("Currency,Earliest_Date,Latest_Date,Total_Days,Approx_Years\n")
            for currency, info in sorted(self.history_depth.items()):
                earliest = info['earliest_date'] or ""
                latest = info['latest_date'] or ""
                f.write(f"{currency},{earliest},{latest},{info['total_days']},{info['approx_years']}\n")
        
        print(f"\n{'=' * 60}")
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´:")
        print(f"   –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç (JSON): {report_path}")
        print(f"   –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç: {text_report_path}")
        print(f"   –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (CSV): {csv_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞."""
    print("=" * 60)
    print("ECB HISTORICAL DEPTH TESTER –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ AbsCur3")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–∫—Ä—ã—Ç–∏–∏
    available_currencies, coverage_path = load_coverage_data()
    print(f"üîç –ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ –≥–ª—É–±–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {len(available_currencies)} –≤–∞–ª—é—Ç.")
    print("-" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–µ—Ä
    tester = ECBHistoryDepthTester(available_currencies, coverage_path)
    
    if tester.run_test():
        tester.save_results()
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\n{'=' * 60}")
        print("–ê–ù–ê–õ–ò–ó –î–õ–Ø –ü–†–û–ï–ö–¢–ê ABScur3:")
        
        currencies_with_depth = []
        currencies_without_depth = []
        
        for currency, info in tester.history_depth.items():
            if info['approx_years'] >= 20:
                currencies_with_depth.append(currency)
            elif info['earliest_date']:
                currencies_without_depth.append((currency, info['approx_years']))
        
        print(f"‚úÖ –í–∞–ª—é—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π >20 –ª–µ—Ç: {len(currencies_with_depth)}/{len(available_currencies)}")
        if currencies_with_depth:
            print(f"   –ü—Ä–∏–º–µ—Ä: {', '.join(sorted(currencies_with_depth)[:5])}...")
        
        if currencies_without_depth:
            print(f"‚ö†Ô∏è  –í–∞–ª—é—Ç —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –≥–ª—É–±–∏–Ω–æ–π: {len(currencies_without_depth)}")
            for currency, years in sorted(currencies_without_depth, key=lambda x: x[1])[:3]:
                print(f"   - {currency}: ~{years} –ª–µ—Ç")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–∂–Ω—ã–µ –≤–∞–ª—é—Ç—ã
        print(f"\nüîç –°–¢–ê–¢–£–° –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –í–ê–õ–Æ–¢:")
        critical_currencies = ['USD', 'JPY', 'GBP', 'CHF', 'CAD', 'AUD', 'CNY']
        for curr in critical_currencies:
            if curr in tester.history_depth:
                info = tester.history_depth[curr]
                status = "‚úÖ" if info['approx_years'] >= 20 else "‚ö†Ô∏è " if info['earliest_date'] else "‚ùå"
                print(f"   {status} {curr}: {info.get('earliest_date', '–ù/–î')} (~{info.get('approx_years', 0)} –ª–µ—Ç)")
        
        print(f"\nüìå –í–´–í–û–î: ECB –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–ª—É–±–æ–∫—É—é –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –≤–∞–ª—é—Ç.")
        print("   –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ ETL-–ø–∞–π–ø–ª–∞–π–Ω.")

if __name__ == "__main__":
    main()